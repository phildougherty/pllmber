#!/usr/bin/env python3
import argparse
import subprocess
import sys
import os

def main():
    parser = argparse.ArgumentParser(description="Process data through an LLM.")
    parser.add_argument('-m', '--model', help="Name of the LLM model to use. If not specified, the default model is used.")
    parser.add_argument('-p', '--prompt', help="Prompt to send to the LLM.")
    parser.add_argument('shorthand_prompt', nargs='?', help="Shorthand method for entering the prompt by putting it in quotes.")

    args = parser.parse_args()

    default_model = os.getenv('PLLMBER_DEFAULT_MODEL', 'llama3.1:8b')
    model = args.model if args.model else default_model
    prompt = args.prompt if args.prompt else args.shorthand_prompt

    if not prompt:
        print("Error: No prompt provided. Use -p option or provide a shorthand prompt in quotes.")
        sys.exit(1)

    data = sys.stdin.read()
    full_input = f"You are an AI agent as a unix command line utility. Your job is to process, slice, dice, augment, transform data that has been sent to you from a unix pipe from another command. Do not discuss anything, your job is to execute and produce results. Your output is short, concise, too the point, and matches easily with other unix command line utilities for further processing. Your output must appear to be that of any other unix command  unless otherwise directed.{prompt}\n\n{data}"

    try:
        result = subprocess.run(
            ["ollama", "run", model, full_input],
            text=True,
            capture_output=True
        )

        if result.returncode != 0:
            print(f"Error: {result.stderr}")
            sys.exit(result.returncode)

        print(result.stdout)
    except FileNotFoundError as e:
        print(f"Error: {e}")
        print("Make sure 'ollama' is correctly installed and available in your PATH.")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

if __name__ == "__main__":
    main()
